# this file is modified from Sighan 2005 bakeoff (CTB) properties file

#
# training and test files
#

trainFile = /u/nlp/data/gale/segtool/stanford-seg/data/train_and_hand_example/trainfordryrunpk.utf8

# map [testMap, trainMap]
#
# you MUST call answer answer
# if you use our reading/writing, call it "word"
# if you write your own, you can call it whatever you want
#
map = char=0,answer=1
backgroundSymbol=1
removeBackgroundSingletonFeatures=true
saveFeatureIndexToDisk=true

#
# if you want to save the model
# you can load a model (instead of trainFile) with loadPath=
#

#
# how to read the input [keep this line]
#

readerAndWriter=edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter

plainTextDocumentReaderAndWriter=edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter

#
# how to do optimization.
# higher QNsize = less time, fewer iterations, more memory
#
useQN = true
QNsize = 15

# This value has been set to be roughly optimal
sigma = 5.0


# use the chinese feature factory
#
featureFactory = edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory


# inputEncoding = GB18030
inputEncoding = UTF-8
outputEncoding = UTF-8

# chinese features
maxLeft=1
useWord1=true
useWord2=true
useFeaturesC4gram=true
useFeaturesCpC4gram=true
useUnicodeType=true
useUnicodeType4gram=true
useUnicodeBlock=true
useShapeStrings=true
useShapeStrings1=true
useShapeStrings3=true
useShapeStrings4=true
useShapeStrings5=true

useDict2=true
usePKChar2=true
usePK=true
useRule2=true
useWordn=true
# normalizationTable=/u/nlp/data/chinesefactfinder/data/chinese-segmenter/norm.simp.utf8


useDictionaryConjunctions=true
expandMidDot=true

keepEnglishWhitespaces=true

#useChPos=true

# printFeatures = ctb-train

# runtime testing
keepAllWhitespaces = true
sighanPostProcessing = true
